const fs = require('fs').promises;
const path = require('path');
const { v4: uuidv4 } = require('uuid');
const GraphService = require('./GraphService');
const dbManager = require('../config/database');
const { validateNode, validateEdge, COLLECTIONS } = require('../models/schemas');

class UploadService {
  static async getDatabase() {
    if (!dbManager.isConnected()) {
      await dbManager.connect();
    }
    return dbManager.getDatabase();
  }

  // íŒŒì¼ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜
  static async processFile(file, options = {}) {
    const uploadId = uuidv4();
    const startTime = Date.now();
    
    try {
      console.log(`ğŸ“ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: ${file.originalname}`);
      
      // ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ìƒì„±
      await this.createUploadHistory({
        uploadId,
        originalFilename: file.originalname,
        fileSize: file.size,
        fileType: path.extname(file.originalname).toLowerCase(),
        uploadMethod: 'file',
        status: 'processing'
      });

      // íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
      let processedData;
      const fileExtension = path.extname(file.originalname).toLowerCase();
      
      switch (fileExtension) {
        case '.csv':
          processedData = await this.processCSVFile(file, options);
          break;
        case '.json':
          processedData = await this.processJSONFile(file, options);
          break;
        case '.pdf':
          processedData = await this.processPDFFile(file, options);
          break;
        default:
          throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: ${fileExtension}`);
      }

      // ê·¸ë˜í”„ ìƒì„±
      const graphResult = await GraphService.createGraph({
        nodes: processedData.nodes,
        edges: processedData.edges,
        metadata: {
          ...processedData.metadata,
          source_file: file.originalname,
          file_type: fileExtension.substring(1),
          upload_method: 'file',
          processing_options: options
        }
      });

      const processingTime = Date.now() - startTime;

      // ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
      await this.updateUploadHistory(uploadId, {
        status: 'completed',
        nodes_created: processedData.nodes.length,
        edges_created: processedData.edges.length,
        processing_time: processingTime,
        graph_id: graphResult.graphId,
        completed_at: new Date().toISOString()
      });

      // ì„ì‹œ íŒŒì¼ ì‚­ì œ
      try {
        await fs.unlink(file.path);
      } catch (unlinkError) {
        console.warn('ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:', unlinkError.message);
      }

      console.log(`âœ… íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: ${file.originalname} (${processingTime}ms)`);

      return {
        uploadId,
        graphId: graphResult.graphId,
        nodes: processedData.nodes.length,
        edges: processedData.edges.length,
        processingTime,
        metadata: processedData.metadata
      };

    } catch (error) {
      console.error(`âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: ${file.originalname}`, error);
      
      // ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
      try {
        await this.updateUploadHistory(uploadId, {
          status: 'failed',
          error_message: error.message,
          completed_at: new Date().toISOString()
        });
      } catch (updateError) {
        console.error('ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:', updateError);
      }

      // ì„ì‹œ íŒŒì¼ ì •ë¦¬
      if (file && file.path) {
        try {
          await fs.unlink(file.path);
        } catch (unlinkError) {
          console.warn('ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:', unlinkError.message);
        }
      }

      throw error;
    }
  }

  // CSV íŒŒì¼ ì²˜ë¦¬
  static async processCSVFile(file, options) {
    try {
      const content = await fs.readFile(file.path, 'utf-8');
      const csvData = this.parseCSV(content);

      if (csvData.length === 0) {
        throw new Error('CSV íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤');
      }

      // CSVë¥¼ ì§€ì‹ê·¸ë˜í”„ë¡œ ë³€í™˜
      const graphData = await this.csvToKnowledgeGraph(csvData, {
        maxKeywords: options.maxKeywords || 10,
        minFrequency: options.minFrequency || 2,
        includeAuthors: options.includeAuthors !== false,
        includeJournals: options.includeJournals !== false
      });

      return {
        nodes: graphData.nodes,
        edges: graphData.edges,
        metadata: {
          title: `Knowledge Graph from ${file.originalname}`,
          description: `Generated from CSV file with ${csvData.length} rows`,
          source_papers: csvData.length
        }
      };

    } catch (error) {
      throw new Error(`CSV ì²˜ë¦¬ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // JSON íŒŒì¼ ì²˜ë¦¬
  static async processJSONFile(file, options) {
    try {
      const content = await fs.readFile(file.path, 'utf-8');
      const jsonData = JSON.parse(content);

      // JSON êµ¬ì¡° ê²€ì¦
      if (!jsonData.nodes || !Array.isArray(jsonData.nodes)) {
        throw new Error('ì˜¬ë°”ë¥¸ ë…¸ë“œ ë°°ì—´ì´ ì—†ìŠµë‹ˆë‹¤');
      }

      if (!jsonData.edges || !Array.isArray(jsonData.edges)) {
        throw new Error('ì˜¬ë°”ë¥¸ ì—£ì§€ ë°°ì—´ì´ ì—†ìŠµë‹ˆë‹¤');
      }

      // ë°ì´í„° ì •ê·œí™”
      const normalizedNodes = jsonData.nodes.map((node, index) => ({
        id: node.id || `node_${index}`,
        label: node.label || node.name || `Node ${index}`,
        size: Math.max(10, Math.min(50, node.size || 20)),
        type: node.type || 'concept',
        attributes: node.attributes || {}
      }));

      const normalizedEdges = jsonData.edges.map(edge => ({
        source: edge.source || edge.from,
        target: edge.target || edge.to,
        weight: Math.max(1, edge.weight || edge.value || 1),
        relationship_type: edge.relationship_type || edge.type || 'RELATED_TO',
        attributes: edge.attributes || {}
      }));

      return {
        nodes: normalizedNodes,
        edges: normalizedEdges,
        metadata: {
          title: jsonData.metadata?.title || `Knowledge Graph from ${file.originalname}`,
          description: jsonData.metadata?.description || 'Imported from JSON file',
          ...jsonData.metadata
        }
      };

    } catch (error) {
      throw new Error(`JSON ì²˜ë¦¬ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // PDF íŒŒì¼ ì²˜ë¦¬ (ê¸°ë³¸ êµ¬í˜„ - ì¶”í›„ í™•ì¥ ê°€ëŠ¥)
  static async processPDFFile(file, options) {
    try {
      // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” PDF íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
      // í˜„ì¬ëŠ” ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
      console.warn('PDF ì²˜ë¦¬ëŠ” í˜„ì¬ ê¸°ë³¸ êµ¬í˜„ì…ë‹ˆë‹¤. ì¶”í›„ PDF.js í†µí•© ì˜ˆì •');
      
      return {
        nodes: [
          {
            id: 'pdf_document',
            label: path.basename(file.originalname, '.pdf'),
            size: 30,
            type: 'document',
            attributes: {
              file_type: 'pdf',
              file_size: file.size
            }
          }
        ],
        edges: [],
        metadata: {
          title: `PDF Document: ${file.originalname}`,
          description: 'PDF file uploaded - full text extraction pending',
          file_type: 'pdf'
        }
      };

    } catch (error) {
      throw new Error(`PDF ì²˜ë¦¬ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // URLì—ì„œ íŒŒì¼ ì²˜ë¦¬
  static async processFromURL(url, options = {}) {
    const uploadId = uuidv4();
    
    try {
      console.log(`ğŸ”— URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘: ${url}`);
      
      // ê°„ë‹¨í•œ URL ë‹¤ìš´ë¡œë“œ êµ¬í˜„ (ì‹¤ì œë¡œëŠ” ë” ê²¬ê³ í•œ êµ¬í˜„ í•„ìš”)
      const response = await fetch(url);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const content = await response.text();
      const filename = path.basename(new URL(url).pathname) || 'downloaded_file';
      const fileExtension = path.extname(filename).toLowerCase();

      // ì„ì‹œ íŒŒì¼ ìƒì„±
      const tempFilePath = path.join(process.env.UPLOAD_DIR || './uploads', `${uploadId}_${filename}`);
      await fs.writeFile(tempFilePath, content);

      // ê°€ìƒ íŒŒì¼ ê°ì²´ ìƒì„±
      const mockFile = {
        originalname: filename,
        path: tempFilePath,
        size: Buffer.byteLength(content, 'utf8')
      };

      // ê¸°ì¡´ íŒŒì¼ ì²˜ë¦¬ ë¡œì§ ì¬ì‚¬ìš©
      return await this.processFile(mockFile, options);

    } catch (error) {
      throw new Error(`URL íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // CSV íŒŒì‹±
  static parseCSV(csvText) {
    const lines = csvText.split('\n').filter(line => line.trim());
    if (lines.length < 2) return [];

    // í—¤ë” ì²˜ë¦¬
    const headers = lines[0].split(',').map(h => 
      h.trim().toLowerCase().replace(/['"]/g, '').replace(/\s+/g, '_')
    );

    const data = [];
    for (let i = 1; i < lines.length; i++) {
      try {
        const values = this.parseCSVLine(lines[i]);
        if (values.length >= headers.length) {
          const row = {};
          headers.forEach((header, index) => {
            row[header] = values[index] ? values[index].trim().replace(/['"]/g, '') : '';
          });
          data.push(row);
        }
      } catch (error) {
        console.warn(`CSV ë¼ì¸ ${i + 1} íŒŒì‹± ì‹¤íŒ¨:`, error.message);
      }
    }

    return data;
  }

  // CSV ë¼ì¸ íŒŒì‹±
  static parseCSVLine(line) {
    const values = [];
    let current = '';
    let inQuotes = false;

    for (let i = 0; i < line.length; i++) {
      const char = line[i];
      if (char === '"') {
        inQuotes = !inQuotes;
      } else if (char === ',' && !inQuotes) {
        values.push(current);
        current = '';
      } else {
        current += char;
      }
    }
    values.push(current);
    return values;
  }

  // CSVë¥¼ ì§€ì‹ê·¸ë˜í”„ë¡œ ë³€í™˜
  static async csvToKnowledgeGraph(papers, config) {
    const nodes = new Map();
    const edges = new Map();
    const paperKeywords = [];

    // ê° ë…¼ë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    papers.forEach((paper, index) => {
      const keywords = new Set();

      // ê¸°ì¡´ í‚¤ì›Œë“œ í•„ë“œì—ì„œ ì¶”ì¶œ
      const keywordFields = ['keywords', 'keyword', 'tags', 'subjects'];
      keywordFields.forEach(field => {
        if (paper[field] && paper[field].trim()) {
          paper[field].split(/[,;|]/)
            .map(k => k.trim().toLowerCase())
            .filter(k => k.length > 2)
            .forEach(k => keywords.add(k));
        }
      });

      // ì œëª©ê³¼ ì´ˆë¡ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
      const titleFields = ['title', 'paper_title', 'article_title'];
      const abstractFields = ['abstract', 'description', 'summary'];
      
      let combinedText = '';
      titleFields.forEach(field => {
        if (paper[field]) combinedText += ' ' + paper[field];
      });
      abstractFields.forEach(field => {
        if (paper[field]) combinedText += ' ' + paper[field];
      });

      if (combinedText.trim()) {
        const extractedKeywords = this.extractKeywords(combinedText, config.maxKeywords);
        extractedKeywords.forEach(kw => keywords.add(kw.word));
      }

      paperKeywords.push({
        paper: paper,
        keywords: Array.from(keywords)
      });
    });

    // ë¹ˆë„ ê³„ì‚° ë° ë…¸ë“œ ìƒì„±
    const keywordFreq = new Map();
    paperKeywords.forEach(pk => {
      pk.keywords.forEach(keyword => {
        keywordFreq.set(keyword, (keywordFreq.get(keyword) || 0) + 1);
      });
    });

    // ìµœì†Œ ë¹ˆë„ ì´ìƒì˜ í‚¤ì›Œë“œë§Œ ë…¸ë“œë¡œ ìƒì„±
    Array.from(keywordFreq.entries())
      .filter(([keyword, freq]) => freq >= config.minFrequency)
      .forEach(([keyword, freq]) => {
        const relatedPapers = paperKeywords
          .filter(pk => pk.keywords.includes(keyword))
          .map(pk => pk.paper);

        const nodeId = `keyword_${keyword.replace(/\s+/g, '_')}`;
        const size = Math.min(50, Math.max(10, freq * 5));

        nodes.set(nodeId, {
          id: nodeId,
          label: keyword,
          type: 'keyword',
          size: size,
          attributes: {
            frequency: freq,
            paper_count: relatedPapers.length,
            related_papers: relatedPapers.slice(0, 5).map(p => 
              p.title || p.paper_title || 'Untitled'
            )
          }
        });
      });

    // ì—£ì§€ ìƒì„± (ë™ì‹œ ì¶œí˜„ ê¸°ë°˜)
    paperKeywords.forEach(pk => {
      const validKeywords = pk.keywords.filter(k => keywordFreq.get(k) >= config.minFrequency);
      
      for (let i = 0; i < validKeywords.length; i++) {
        for (let j = i + 1; j < validKeywords.length; j++) {
          const kw1 = validKeywords[i];
          const kw2 = validKeywords[j];
          
          const id1 = `keyword_${kw1.replace(/\s+/g, '_')}`;
          const id2 = `keyword_${kw2.replace(/\s+/g, '_')}`;
          const edgeKey = id1 < id2 ? `${id1}__${id2}` : `${id2}__${id1}`;
          
          if (edges.has(edgeKey)) {
            edges.get(edgeKey).weight++;
          } else {
            edges.set(edgeKey, {
              source: id1,
              target: id2,
              weight: 1,
              relationship_type: 'CO_OCCURS'
            });
          }
        }
      }
    });

    return {
      nodes: Array.from(nodes.values()),
      edges: Array.from(edges.values())
    };
  }

  // í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
  static extractKeywords(text, maxKeywords = 10) {
    const words = text.toLowerCase()
      .replace(/[^\w\s]/g, ' ')
      .split(/\s+/)
      .filter(word => word.length > 2);

    const wordCount = {};
    words.forEach(word => {
      wordCount[word] = (wordCount[word] || 0) + 1;
    });

    return Object.entries(wordCount)
      .sort((a, b) => b[1] - a[1])
      .slice(0, maxKeywords)
      .map(([word, count]) => ({ word, count }));
  }

  // ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ìƒì„±
  static async createUploadHistory(historyData) {
    const db = await this.getDatabase();
    
    try {
      const collection = db.collection(COLLECTIONS.UPLOAD_HISTORY);
      const doc = {
        _key: historyData.uploadId,
        upload_id: historyData.uploadId,
        original_filename: historyData.originalFilename,
        file_size: historyData.fileSize,
        file_type: historyData.fileType,
        upload_method: historyData.uploadMethod,
        status: historyData.status,
        created_at: new Date().toISOString()
      };

      return await collection.save(doc);
    } catch (error) {
      throw new Error(`ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
  static async updateUploadHistory(uploadId, updateData) {
    const db = await this.getDatabase();
    
    try {
      const collection = db.collection(COLLECTIONS.UPLOAD_HISTORY);
      return await collection.update(uploadId, updateData);
    } catch (error) {
      console.error(`ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
  static async getUploadHistory(options = {}) {
    const db = await this.getDatabase();
    const { limit = 20, offset = 0 } = options;

    try {
      const query = `
        FOR doc IN ${COLLECTIONS.UPLOAD_HISTORY}
        SORT doc.created_at DESC
        LIMIT @offset, @limit
        RETURN doc
      `;

      const result = await db.query(query, { limit, offset });
      return await result.all();
    } catch (error) {
      throw new Error(`ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // íŠ¹ì • ì—…ë¡œë“œ ê²°ê³¼ ì¡°íšŒ
  static async getUploadResult(uploadId) {
    const db = await this.getDatabase();

    try {
      const collection = db.collection(COLLECTIONS.UPLOAD_HISTORY);
      return await collection.document(uploadId);
    } catch (error) {
      if (error.isArangoError && error.errorNum === 1202) {
        return null;
      }
      throw new Error(`ì—…ë¡œë“œ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: ${error.message}`);
    }
  }

  // ì—…ë¡œë“œ ì‚­ì œ
  static async deleteUpload(uploadId) {
    const db = await this.getDatabase();

    try {
      // ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
      const uploadHistory = await this.getUploadResult(uploadId);
      if (!uploadHistory) {
        throw new Error('ì—…ë¡œë“œ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
      }

      // ê´€ë ¨ ê·¸ë˜í”„ ë°ì´í„° ì‚­ì œ (ì„ íƒì )
      if (uploadHistory.graph_id) {
        // ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìì—ê²Œ í™•ì¸ì„ ë°›ì•„ì•¼ í•¨
        console.log(`ê·¸ë˜í”„ ${uploadHistory.graph_id} ì‚­ì œëŠ” ë³„ë„ë¡œ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤`);
      }

      // ì—…ë¡œë“œ íˆìŠ¤í† ë¦¬ ì‚­ì œ
      const collection = db.collection(COLLECTIONS.UPLOAD_HISTORY);
      await collection.remove(uploadId);

      return { message: 'ì—…ë¡œë“œ ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤' };
    } catch (error) {
      throw new Error(`ì—…ë¡œë“œ ì‚­ì œ ì‹¤íŒ¨: ${error.message}`);
    }
  }
}

module.exports = UploadService;